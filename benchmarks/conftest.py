"""
Pydantic-Resolve Benchmark Suite - Common Fixtures and Utilities

å…±äº«çš„ fixtures å’Œè¾…åŠ©å‡½æ•°
"""


# ============================================================================
# Helper Functions
# ============================================================================

def measure_performance(result, elapsed, node_count=None, item_count=None):
    """æ‰“å°æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n  âœ… Test completed in {elapsed:.4f}s")
    if node_count:
        print(f"  ðŸ“Š Nodes processed: {node_count}")
        if elapsed > 0:
            print(f"  ðŸ“ˆ Average: {elapsed/node_count*1000:.2f}ms per node")
    if item_count:
        print(f"  ðŸ“¦ Total items: {item_count}")


def assert_performance(elapsed, max_time, test_name: str):
    """æ€§èƒ½æ–­è¨€"""
    assert elapsed < max_time, (
        f"{test_name} too slow: {elapsed:.4f}s (expected < {max_time:.4f}s)"
    )


# ============================================================================
# Pytest Configuration
# ============================================================================

def pytest_configure(config):
    """é…ç½® pytest æ ‡è®°"""
    config.addinivalue_line(
        "markers", "benchmark: mark test as benchmark test"
    )
