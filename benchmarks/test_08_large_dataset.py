"""
Benchmark 8: Large Datasets

æµ‹è¯•å¤§æ•°æ®é›†å¤„ç†çš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚

æµ‹è¯•åœºæ™¯:
- 1000+ å¯¹è±¡å¤„ç†
- é€’å½’å…³è”åŠ è½½
- å†…å­˜ä½¿ç”¨æƒ…å†µ

æ€§èƒ½ç›®æ ‡: < 2s for 1000 products with 3 related each
"""

import time
import asyncio
import pytest
from typing import List
from pydantic import BaseModel

from pydantic_resolve import Resolver
from .conftest import measure_performance, assert_performance


# ============================================================================
# Test Data Classes
# ============================================================================

class RelatedProduct(BaseModel):
    """ç›¸å…³äº§å“ - ä¸å¸¦é€’å½’è§£æ"""
    id: int
    name: str
    category: str
    price: float = 0.0


class Product(BaseModel):
    """äº§å“ - å¸¦å…³è”äº§å“"""
    id: int
    name: str
    category: str
    price: float = 0.0

    related_products: List[RelatedProduct] = []
    async def resolve_related_products(self) -> List[RelatedProduct]:
        # æ¨¡æ‹Ÿå°‘é‡ç›¸å…³äº§å“
        await asyncio.sleep(0.001)
        return [
            RelatedProduct(
                id=i,
                name=f'Related {i}',
                category=f'Cat {i % 10}',
                price=float(i * 10)
            )
            for i in range(3)
        ]


class LargeItem(BaseModel):
    """å¤§æ‰¹é‡é¡¹"""
    id: int
    value: int

    calculated: int = 0
    def post_calculated(self):
        return self.value * 2


# ============================================================================
# Benchmarks
# ============================================================================

@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_large_dataset_basic():
    """
    Benchmark: åŸºç¡€å¤§æ•°æ®é›†

    æµ‹è¯•ç›®æ ‡:
    - æµ‹è¯• 1000+ å¯¹è±¡çš„è§£ææ€§èƒ½
    - éªŒè¯å¯æ‰©å±•æ€§

    åœºæ™¯:
    - 1000 products
    - æ¯ä¸ª product æœ‰ 3 related products
    - æ€»èŠ‚ç‚¹: 1000 + 3000 = 4000

    é¢„æœŸ: < 2s
    """
    products = [
        Product(
            id=i,
            name=f'Product {i}',
            category=f'Cat {i % 10}',
            price=float(i * 10)
        )
        for i in range(1000)
    ]

    start = time.perf_counter()
    result = await Resolver().resolve(products)
    elapsed = time.perf_counter() - start

    assert len(result) == 1000

    # è®¡ç®—æ€»èŠ‚ç‚¹æ•° (æ ¹èŠ‚ç‚¹ + ç¬¬ä¸€å±‚ç›¸å…³äº§å“)
    total_nodes = len(result) + sum(len(p.related_products) for p in result)
    assert total_nodes == 4000

    measure_performance(result, elapsed, node_count=1000, item_count=total_nodes)
    print(f"  ğŸ“¦ Total objects resolved: {total_nodes}")
    print(f"  ğŸ“ˆ Average: {elapsed/total_nodes*1000:.3f}ms per object")

    assert_performance(elapsed, 2.0, "Large dataset basic")


@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_large_dataset_with_post():
    """
    Benchmark: å¤§æ•°æ®é›† + Post è®¡ç®—

    æµ‹è¯•ç›®æ ‡:
    - æµ‹è¯•å¤§é‡å¯¹è±¡çš„è®¡ç®—å¼€é”€
    - éªŒè¯ post æ–¹æ³•åœ¨å¤§æ•°æ®é›†ä¸Šçš„æ€§èƒ½

    åœºæ™¯:
    - 2000 items
    - æ¯ä¸ªéƒ½æœ‰ post è®¡ç®—

    é¢„æœŸ: < 1s
    """
    items = [LargeItem(id=i, value=i) for i in range(2000)]

    start = time.perf_counter()
    result = await Resolver().resolve(items)
    elapsed = time.perf_counter() - start

    assert len(result) == 2000
    assert all(i.calculated == i.value * 2 for i in result)

    measure_performance(result, elapsed, node_count=2000)

    assert_performance(elapsed, 1.0, "Large dataset with post")


@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_very_large_dataset():
    """
    Benchmark: è¶…å¤§æ•°æ®é›†

    æµ‹è¯•ç›®æ ‡:
    - æµ‹è¯•æç«¯æƒ…å†µçš„æ€§èƒ½
    - ç¡®å®šæ€§èƒ½ç“¶é¢ˆ

    åœºæ™¯:
    - 5000 items

    é¢„æœŸ: < 5s (å¯ä»¥æ¥å—ï¼Œä½†åº”è¯¥ä¼˜åŒ–)
    """
    items = [LargeItem(id=i, value=i) for i in range(5000)]

    start = time.perf_counter()
    result = await Resolver().resolve(items)
    elapsed = time.perf_counter() - start

    assert len(result) == 5000

    measure_performance(result, elapsed, node_count=5000)
    print("  âš ï¸  Large dataset test")

    # æ”¾å®½æ€§èƒ½è¦æ±‚
    assert_performance(elapsed, 5.0, "Very large dataset")


@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_large_dataset_list_input():
    """
    Benchmark: åˆ—è¡¨è¾“å…¥çš„å¤§æ•°æ®é›†

    æµ‹è¯•ç›®æ ‡:
    - æµ‹è¯•ä»åˆ—è¡¨å¼€å§‹çš„è§£æ
    - éªŒè¯ list å’Œå•å¯¹è±¡æ€§èƒ½å·®å¼‚

    é¢„æœŸ: < 2s for 1000 products
    """
    products = [
        Product(
            id=i,
            name=f'Product {i}',
            category=f'Cat {i % 10}',
            price=float(i * 10)
        )
        for i in range(1000)
    ]

    start = time.perf_counter()
    result = await Resolver().resolve(products)  # list input
    elapsed = time.perf_counter() - start

    assert len(result) == 1000

    total_nodes = len(result) + sum(len(p.related_products) for p in result)
    measure_performance(result, elapsed, node_count=1000, item_count=total_nodes)

    assert_performance(elapsed, 2.0, "Large dataset list input")


@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_large_dataset_simple_objects():
    """
    Benchmark: å¤§é‡ç®€å•å¯¹è±¡

    æµ‹è¯•ç›®æ ‡:
    - æµ‹è¯•æ²¡æœ‰å…³è”çš„ç®€å•å¯¹è±¡æ€§èƒ½
    - ç¡®å®šåŸºç¡€å¼€é”€

    é¢„æœŸ: < 1s for 10000 simple objects
    """

    class SimpleProduct(BaseModel):
        id: int
        name: str
        price: float

    products = [
        SimpleProduct(id=i, name=f'Product {i}', price=float(i))
        for i in range(10000)
    ]

    start = time.perf_counter()
    result = await Resolver().resolve(products)
    elapsed = time.perf_counter() - start

    assert len(result) == 10000

    measure_performance(result, elapsed, node_count=10000)
    print(f"  ğŸ“Š Throughput: {len(result)/elapsed:.0f} objects/second")

    assert_performance(elapsed, 1.0, "Large simple objects")
