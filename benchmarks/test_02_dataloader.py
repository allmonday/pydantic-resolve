"""
Benchmark 2: DataLoader Batch Loading

æµ‹è¯• DataLoader æ‰¹é‡åŠ è½½æ€§èƒ½ï¼ŒéªŒè¯ N+1 æŸ¥è¯¢ä¼˜åŒ–æ•ˆæœã€‚

æµ‹è¯•åœºæ™¯:
- ä¸€å¯¹ä¸€å…³ç³»åŠ è½½
- æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–
- ç¼“å­˜æ•ˆæœ

æ€§èƒ½ç›®æ ‡: < 0.5s for 1000 tasks with 10 unique users
æ€§èƒ½æå‡: ~100x (1000 queries -> 10 queries)
"""

import time
import asyncio
import pytest
from typing import List, Optional
from pydantic import BaseModel
from aiodataloader import DataLoader

from pydantic_resolve import Resolver, LoaderDepend
from .conftest import measure_performance, assert_performance


# ============================================================================
# Test Data and Loaders
# ============================================================================

# æ¨¡æ‹Ÿæ•°æ®åº“
user_db = {
    i: {'id': i, 'name': f'User {i}', 'email': f'user{i}@example.com'}
    for i in range(100)
}

task_db = {
    i: {'id': i, 'title': f'Task {i}', 'user_id': i % 10}
    for i in range(1000)
}


class SimpleUser(BaseModel):
    """ç®€å•çš„ç”¨æˆ·æ¨¡å‹"""
    id: int
    name: str
    email: str


class UserLoader(DataLoader):
    """ç”¨æˆ·æ‰¹é‡åŠ è½½å™¨"""
    async def batch_load_fn(self, keys: List[int]):
        await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        return [user_db.get(k) for k in keys]


class TaskWithUser(BaseModel):
    """å¸¦ç”¨æˆ·çš„ä»»åŠ¡"""
    id: int
    title: str
    user_id: int

    owner: Optional[SimpleUser] = None
    async def resolve_owner(self, loader=LoaderDepend(UserLoader)):
        return await loader.load(self.user_id)


# ============================================================================
# Benchmarks
# ============================================================================

@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_dataloader_one_to_one():
    """
    Benchmark: DataLoader ä¸€å¯¹ä¸€å…³ç³»åŠ è½½

    æµ‹è¯•ç›®æ ‡:
    - éªŒè¯æ‰¹é‡åŠ è½½æ•ˆæœ
    - æµ‹é‡ N+1 æŸ¥è¯¢ä¼˜åŒ–

    åœºæ™¯:
    - 1000 tasks
    - 10 unique users (user_id = task_id % 10)
    - é¿å… 1000 æ¬¡å•ç‹¬æŸ¥è¯¢

    é¢„æœŸ: < 0.5s
    ä¼˜åŒ–æ•ˆæœ: 1000 queries -> 10 queries
    """
    tasks = [TaskWithUser(
        id=i,
        title=f'Task {i}',
        user_id=i % 10
    ) for i in range(1000)]

    start = time.perf_counter()
    result = await Resolver().resolve(tasks)
    elapsed = time.perf_counter() - start

    assert len(result) == 1000

    # éªŒè¯æ•°æ®æ­£ç¡®æ€§
    unique_users = len(set(t.user_id for t in result))
    assert unique_users == 10, f"Expected 10 unique users, got {unique_users}"

    loaded_users = sum(1 for t in result if t.owner is not None)
    assert loaded_users == 1000, f"Expected 1000 loaded users, got {loaded_users}"

    measure_performance(result, elapsed, node_count=1000, item_count=1000)
    print(f"  ğŸš€ Batch loading prevented {1000} queries")
    print("  ğŸ“Š Queries reduced from 1000 to ~10 (100x improvement)")

    assert_performance(elapsed, 0.5, "DataLoader one-to-one")


@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_dataloader_caching():
    """
    Benchmark: DataLoader ç¼“å­˜æ•ˆæœ

    æµ‹è¯•ç›®æ ‡:
    - éªŒè¯ DataLoader çš„ç¼“å­˜æœºåˆ¶
    - æµ‹é‡é‡å¤åŠ è½½åŒä¸€å¯¹è±¡çš„æ€§èƒ½

    åœºæ™¯:
    - å¤šä¸ªä»»åŠ¡å¼•ç”¨åŒä¸€ä¸ªç”¨æˆ·
    - éªŒè¯åªåŠ è½½ä¸€æ¬¡

    é¢„æœŸ: < 0.3s
    """
    # åˆ›å»ºæ›´å¤šé‡å¤å¼•ç”¨çš„åœºæ™¯
    tasks = [TaskWithUser(
        id=i,
        title=f'Task {i}',
        user_id=i % 5  # åªä½¿ç”¨ 5 ä¸ªç”¨æˆ·
    ) for i in range(500)]

    start = time.perf_counter()
    result = await Resolver().resolve(tasks)
    elapsed = time.perf_counter() - start

    assert len(result) == 500

    unique_users = len(set(t.user_id for t in result))
    assert unique_users == 5

    loaded_users = sum(1 for t in result if t.owner is not None)
    assert loaded_users == 500

    measure_performance(result, elapsed, node_count=500, item_count=500)
    print(f"  ğŸš€ Batch loading: {500} tasks -> ~5 queries")
    print(f"  ğŸ“Š Cache efficiency: {500/5:.1f}x")

    assert_performance(elapsed, 0.3, "DataLoader caching")


@pytest.mark.asyncio
@pytest.mark.benchmark
async def test_dataloader_small_batch():
    """
    Benchmark: DataLoader å°æ‰¹é‡åŠ è½½

    æµ‹è¯•ç›®æ ‡:
    - æµ‹è¯•å°‘é‡æ•°æ®çš„æ‰¹é‡åŠ è½½
    - éªŒè¯æ‰¹é‡åŠ è½½åœ¨å°æ•°æ®é›†ä¸Šçš„å¼€é”€

    åœºæ™¯:
    - 100 tasks
    - 10 unique users

    é¢„æœŸ: < 0.1s
    """
    tasks = [TaskWithUser(
        id=i,
        title=f'Task {i}',
        user_id=i % 10
    ) for i in range(100)]

    start = time.perf_counter()
    result = await Resolver().resolve(tasks)
    elapsed = time.perf_counter() - start

    assert len(result) == 100

    loaded_users = sum(1 for t in result if t.owner is not None)
    assert loaded_users == 100

    measure_performance(result, elapsed, node_count=100)
    print("  ğŸš€ Batch loading: 100 tasks -> ~10 queries")

    assert_performance(elapsed, 0.1, "DataLoader small batch")
